{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score, roc_auc_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk import sent_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "from src.preprocessor import GildPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordCounter(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        return None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        Z = np.array([\n",
    "            self.count_text(doc) for doc in X\n",
    "        ])\n",
    "        return Z.reshape(-1, 1)\n",
    "    \n",
    "    def count_text(self, doc):\n",
    "        clean1 = re.sub(r'['+string.punctuation + '’—”'+']', \"\", doc.lower())\n",
    "        clean2 = re.sub(r'\\W+', ' ', clean1)\n",
    "        return len(clean2.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordCounterSubjectivity(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.subj_toks = [\"i\", \"me\", \"ive\", \"im\", \"my\", \"mine\"]\n",
    "        return None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        word_counts = np.array([\n",
    "            len((self.simplify_text(doc)).split()) for doc in X\n",
    "        ])\n",
    "        subj_scores = np.array([\n",
    "        \tself.subjectivity_score(doc, word_counts[i]) for i, doc in enumerate(X)\n",
    "        ])\n",
    "        word_counts = word_counts.reshape(-1, 1)\n",
    "        subj_scores = subj_scores.reshape(-1, 1)\n",
    "        return np.hstack((word_counts, subj_scores))\n",
    "    \n",
    "    def simplify_text(self, doc):\n",
    "        clean1 = re.sub(r'['+string.punctuation + '’—”'+']', \"\", doc.lower())\n",
    "        clean2 = re.sub(r'\\W+', ' ', clean1)\n",
    "        return clean2\n",
    "\n",
    "    def subjectivity_score(self, doc, wc):\n",
    "        subj_counter = 0\n",
    "        for word in self.simplify_text(doc):\n",
    "            if word in self.subj_toks:\n",
    "                subj_counter += 1\n",
    "        return subj_counter/wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity(words):\n",
    "    return words\n",
    "\n",
    "w = 50 # The weight for the positive class\n",
    "\n",
    "model = Pipeline([\n",
    "    ('normalizer', GildPreprocessor()),\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=identity, preprocessor=None, lowercase=False)),\n",
    "    ('trees', RandomForestClassifier(random_state=0, n_jobs=-1, class_weight={0: 1, 1: w}))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Pipeline([\n",
    "    ('preprocess_union', FeatureUnion([\n",
    "    \t\t('term_freq_feature', Pipeline([\n",
    "    \t\t\t('normalizer', GildPreprocessor()),\n",
    "    \t\t\t('vectorizer', TfidfVectorizer(tokenizer=identity, preprocessor=None, lowercase=False))\n",
    "    \t\t\t])),\n",
    "    \t\t('word_counter', WordCounter())\n",
    "    \t])),\n",
    "    ('trees', RandomForestClassifier(random_state=0, n_jobs=-1, class_weight={0: 1, 1: w}))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Pipeline([\n",
    "    ('preprocess_union', FeatureUnion([\n",
    "    \t\t('term_freq_feature', Pipeline([\n",
    "    \t\t\t('normalizer', GildPreprocessor()),\n",
    "    \t\t\t('vectorizer', TfidfVectorizer(tokenizer=identity, preprocessor=None, lowercase=False))\n",
    "    \t\t\t])),\n",
    "    \t\t('word_counter', WordCounterSubjectivity())\n",
    "    \t])),\n",
    "    ('trees', RandomForestClassifier(random_state=0, n_jobs=-1, class_weight={0: 1, 1: w}))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/askreddit_top_15_sm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = df['body'].tolist()\n",
    "#y = df['target'].tolist()\n",
    "X = df['body']\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('normalizer', GildPreprocessor(lower=True, strip=True)),\n",
       "                ('vectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=False, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_wor...\n",
       "                 RandomForestClassifier(bootstrap=True,\n",
       "                                        class_weight={0: 1, 1: 50},\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=-1,\n",
       "                                        oob_score=False, random_state=0,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.891697  0.935606  0.913124       264\n",
      "           1   0.260870  0.166667  0.203390        36\n",
      "\n",
      "    accuracy                       0.843333       300\n",
      "   macro avg   0.576283  0.551136  0.558257       300\n",
      "weighted avg   0.815997  0.843333  0.827956       300\n",
      "\n",
      "[0 1]\n",
      "0.8433333333333334\n",
      "0.537773569023569\n",
      "6 17 247 30\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "print(classification_report(y_test, pred, digits=6))\n",
    "# Is our model still predicting just one class?\n",
    "print( np.unique( pred ) )\n",
    " \n",
    "# How's our accuracy?\n",
    "print( accuracy_score(y_test, pred) )\n",
    " \n",
    "# What about AUROC?\n",
    "prob_y = model.predict_proba(X_test)\n",
    "prob_y = [p[1] for p in prob_y]\n",
    "print( roc_auc_score(y_test, prob_y) )\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(tp, fp, tn, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 1.09118354e-04, 1.64289661e-07, ...,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.steps[2][1].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocess_union',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('term_freq_feature',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('normalizer',\n",
       "                                                                  GildPreprocessor(lower=True,\n",
       "                                                                                   strip=True)),\n",
       "                                                                 ('vectorizer',\n",
       "                                                                  TfidfVectorizer(analyzer='word',\n",
       "                                                                                  binary=False,\n",
       "                                                                                  decode_error='strict',\n",
       "                                                                                  dtype=<class 'numpy.float64'>,\n",
       "                                                                                  encoding='utf-8',\n",
       "                                                                                  input='content',\n",
       "                                                                                  lowercase=Fa...\n",
       "                 RandomForestClassifier(bootstrap=True,\n",
       "                                        class_weight={0: 1, 1: 50},\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=-1,\n",
       "                                        oob_score=False, random_state=0,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.883636  0.920455  0.901670       264\n",
      "           1   0.160000  0.111111  0.131148        36\n",
      "\n",
      "    accuracy                       0.823333       300\n",
      "   macro avg   0.521818  0.515783  0.516409       300\n",
      "weighted avg   0.796800  0.823333  0.809207       300\n",
      "\n",
      "[0 1]\n",
      "0.8233333333333334\n",
      "0.537773569023569\n",
      "4 21 243 32\n"
     ]
    }
   ],
   "source": [
    "pred = model2.predict(X_test)\n",
    "print(classification_report(y_test, pred, digits=6))\n",
    "# Is our model still predicting just one class?\n",
    "print( np.unique( pred ) )\n",
    " \n",
    "# How's our accuracy?\n",
    "print( accuracy_score(y_test, pred) )\n",
    " \n",
    "# What about AUROC?\n",
    "prob_y = model.predict_proba(X_test)\n",
    "prob_y = [p[1] for p in prob_y]\n",
    "print( roc_auc_score(y_test, prob_y) )\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(tp, fp, tn, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocess_union',\n",
       "                 FeatureUnion(n_jobs=None,\n",
       "                              transformer_list=[('term_freq_feature',\n",
       "                                                 Pipeline(memory=None,\n",
       "                                                          steps=[('normalizer',\n",
       "                                                                  GildPreprocessor(lower=True,\n",
       "                                                                                   strip=True)),\n",
       "                                                                 ('vectorizer',\n",
       "                                                                  TfidfVectorizer(analyzer='word',\n",
       "                                                                                  binary=False,\n",
       "                                                                                  decode_error='strict',\n",
       "                                                                                  dtype=<class 'numpy.float64'>,\n",
       "                                                                                  encoding='utf-8',\n",
       "                                                                                  input='content',\n",
       "                                                                                  lowercase=Fa...\n",
       "                 RandomForestClassifier(bootstrap=True,\n",
       "                                        class_weight={0: 1, 1: 50},\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=-1,\n",
       "                                        oob_score=False, random_state=0,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.884615  0.958333  0.920000       264\n",
      "           1   0.214286  0.083333  0.120000        36\n",
      "\n",
      "    accuracy                       0.853333       300\n",
      "   macro avg   0.549451  0.520833  0.520000       300\n",
      "weighted avg   0.804176  0.853333  0.824000       300\n",
      "\n",
      "[0 1]\n",
      "0.8533333333333334\n",
      "0.537773569023569\n",
      "3 11 253 33\n"
     ]
    }
   ],
   "source": [
    "pred = model3.predict(X_test)\n",
    "print(classification_report(y_test, pred, digits=6))\n",
    "# Is our model still predicting just one class?\n",
    "print( np.unique( pred ) )\n",
    " \n",
    "# How's our accuracy?\n",
    "print( accuracy_score(y_test, pred) )\n",
    " \n",
    "# What about AUROC?\n",
    "prob_y = model.predict_proba(X_test)\n",
    "prob_y = [p[1] for p in prob_y]\n",
    "print( roc_auc_score(y_test, prob_y) )\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(tp, fp, tn, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(model3, param_grid={\n",
    "    'preprocess_union__term_freq_feature__vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'trees__n_estimators': [50, 100, 200],\n",
    "}, scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preprocess_union',\n",
       "                                        FeatureUnion(n_jobs=None,\n",
       "                                                     transformer_list=[('term_freq_feature',\n",
       "                                                                        Pipeline(memory=None,\n",
       "                                                                                 steps=[('normalizer',\n",
       "                                                                                         GildPreprocessor(lower=True,\n",
       "                                                                                                          strip=True)),\n",
       "                                                                                        ('vectorizer',\n",
       "                                                                                         TfidfVectorizer(analyzer='word',\n",
       "                                                                                                         binary=False,\n",
       "                                                                                                         decode_error='strict',\n",
       "                                                                                                         dtype=<cl...\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators=10,\n",
       "                                                               n_jobs=-1,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=0,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'preprocess_union__term_freq_feature__vectorizer__ngram_range': [(1,\n",
       "                                                                                           1),\n",
       "                                                                                          (1,\n",
       "                                                                                           2),\n",
       "                                                                                          (1,\n",
       "                                                                                           3)],\n",
       "                         'trees__n_estimators': [50, 100, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='recall', verbose=0)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
